{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "import mnist_reader\n",
    "from scipy import optimize as op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo para convertir un array plano de thetas en matrices con sus shapes correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflate_matrixes(flat_thetas, shapes):\n",
    "    layers = len(shapes) + 1\n",
    "    sizes = [shape[0] * shape[1] for shape in shapes]\n",
    "    steps = np.zeros(layers, dtype=int)\n",
    "\n",
    "    for i in range(layers - 1):\n",
    "        steps[i + 1] = steps[i] + sizes[i]\n",
    "\n",
    "    return [\n",
    "        flat_thetas[steps[i]: steps[i + 1]].reshape(*shapes[i])\n",
    "        for i in range(layers - 1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo feed_forward Matricial para obtener las salidas de cada capa de neuronas de cada una de las 60000 pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(thetas, X):\n",
    "    a = [X]\n",
    "\n",
    "    for i in range(len(thetas)):\n",
    "        a.append(\n",
    "            sigmoid(\n",
    "                np.matmul(\n",
    "                    np.hstack((\n",
    "                        np.ones(len(X)).reshape(len(X), 1),\n",
    "                        a[i]\n",
    "                    )), thetas[i].T\n",
    "                )\n",
    "            )            \n",
    "        )\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion de costo para la optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(flat_thetas, shapes, X, Y):\n",
    "    a = feed_forward(\n",
    "        inflate_matrixes(flat_thetas, shapes),\n",
    "        X\n",
    "    )\n",
    "    return -(Y * np.log(a[-1]) + (1 - Y) * np.log(1 - a[-1])).sum() / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo back propagation para obtener el gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(flat_thetas, shapes, X, Y):\n",
    "    m, layers = len(X), len(shapes) + 1\n",
    "    thetas = inflate_matrixes(flat_thetas, shapes)\n",
    "    \n",
    "    # Paso 2.2\n",
    "    a = feed_forward(thetas, X)\n",
    "\n",
    "    # Paso 2.3\n",
    "    deltas = [*range(layers - 1), a[-1] - Y]\n",
    "    \n",
    "    # Paso 2.4\n",
    "    for i in range(layers - 2, 0, -1):\n",
    "        deltas[i] = np.matmul((deltas[i + 1], np.delete(thetas[i], 0, 1))) * (a[i] * (1 - a[i]))\n",
    "\n",
    "    # Paso 2.5 y 3\n",
    "    Deltas = []\n",
    "    for i in range(layers - 1):\n",
    "        Deltas.append(\n",
    "            ( \n",
    "            np.matmul(\n",
    "                deltas[i + 1].T,\n",
    "                np.hstack((\n",
    "                    np.ones(len(a[i])).reshape(len(a[i]), 1),\n",
    "                    a[i]))\n",
    "                    )\n",
    "            ) / m\n",
    "        )\n",
    "    Deltas = np.asarray(Deltas)\n",
    "\n",
    "    return flatten_list_of_arrays(\n",
    "        Deltas\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion Simboide para pasar las entradas de cada capa a las salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo para aplanar matrices y dejarlas en un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_list_of_arrays = lambda list_of_arrays: reduce(\n",
    "    lambda acc, v: np.array([*acc.flatten(), *v.flatten()]),\n",
    "    list_of_arrays\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias al metodo de load_mnist obtenemos directamente 60000 datos de entrenamiento con sus 784 pixeles cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ademas de tener los datos de prueba que en este caso son 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento 60000\n",
    "X, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "# Datos de prueba 10000\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "# Reajuste de los datos\n",
    "X = X/1000.0\n",
    "# Obtencion de m\n",
    "m,_ = X.shape\n",
    "# Remodelado de las respuestas para poder comparar con el resultado obtenido\n",
    "y_train = y_train.reshape(m,1)\n",
    "Y = (y_train == np.array(range(10))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se establece la cantidad de neuronas y de capas.\n",
    "En este caso seran 784 en la capa de entrada, 125 en la capa oculta y 10 en la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de red neuronal con 3 capas\n",
    "NEURAL_NET = np.array([\n",
    "    784,\n",
    "    125,\n",
    "    10\n",
    "])\n",
    "# Shapes de las matrices de transicion\n",
    "theta_shapes = np.hstack((\n",
    "    NEURAL_NET[1:].reshape(len(NEURAL_NET) - 1, 1),\n",
    "    (NEURAL_NET[:-1] + 1).reshape(len(NEURAL_NET) - 1, 1)\n",
    "))\n",
    "# Creacion de matrices de transicion y aplanamiento de las mismas\n",
    "flat_thetas = flatten_list_of_arrays([\n",
    "    np.random.rand(*theta_shape) * 0.01\n",
    "    for theta_shape in theta_shapes\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usa minimize para optimizar la funcion encontrando las mejores Thetas posibles para esta red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/Desktop/Inteligencia/RedesNeuronales/Lab2/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/home/gustavo/Desktop/Inteligencia/RedesNeuronales/Lab2/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Funcion de optimizacion pide Costo, Thetas, Shapes, X, Y y el Gradiente\n",
    "result = op.minimize(\n",
    "    fun = cost_function,\n",
    "    x0 = flat_thetas,\n",
    "    args=(theta_shapes, X, Y),\n",
    "    method='L-BFGS-B',\n",
    "    jac= back_propagation,\n",
    "    options={'disp': True, 'maxiter': 3000}\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobacion de optimizacion excitosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: nan\n",
       " hess_inv: <99385x99385 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-1.05977143e-06,  9.64977519e-12, -1.34429853e-10, ...,\n",
       "        4.12338655e-07,  1.39474466e-08,  9.18838184e-07])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 13166\n",
       "      nit: 1891\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 2.61400345e+00,  2.68167751e-03, -5.65938327e-02, ...,\n",
       "        1.06486890e+01, -4.72983009e-01, -3.45644538e+00])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99385"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetasResult = result.x\n",
    "thetasResult.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda las mejores Thetas en un txt para usarlas luego en el test del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('thetasR.txt', thetasResult, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetasResult = np.loadtxt('thetasR.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizara un test para comprobar que tan bien le fue al modelo y revisar si existe algun problema de overfitting o de underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De igual manera se ajustan los datos para ser trabajados en la red neuronal \n",
    "X_test = X_test/1000\n",
    "m,_ = X_test.shape\n",
    "y_test = y_test.reshape(m,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las thetas que se calcularon previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_thetas_top = thetasResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se les da su forma correspondiente en matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "superThetas = inflate_matrixes(flat_thetas_top,theta_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con todos los parametros listos se realiza el feed_forward para tener la prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = feed_forward(superThetas, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene la salida de la ultima capa y se modela para poder analizar la informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen la nuerona maxima de cada dato de test para obtener la prediccioni\n",
    "maximos = np.argmax(a[-1], axis = 1).reshape(m,1)\n",
    "# Se compara con los resultados verdaderos\n",
    "correct = ((maximos == y_test)*1).sum()\n",
    "# Se saca el porcentaje de aciertos\n",
    "porBuenos = (correct/m)*100\n",
    "# Y el de errores\n",
    "porMalos = 100.0 - porBuenos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo un 86.98% de aciertos lo cual es aceptable y un valor cercano al teorico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.98"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porBuenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.019999999999996"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porMalos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener un modelo que haya acertado el 86.98% de los datos lo considero màs que aceptable ya que demuestra que en efecto se entrenò de una buena manera con la capa oculta que se le asignò con 125 neuronas. Ademàs del bias que se le agregò para evitar los problemas de overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
